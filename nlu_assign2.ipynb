{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "nlu-assign2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZEK70VgKdJm"
      },
      "source": [
        "import pandas as pd\n",
        "import conll\n",
        "import spacy\n",
        "import numpy\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from spacy.tokens import Token, Doc\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOL4ztz6KdJt"
      },
      "source": [
        "path=\"test.txt\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsYw0H0DKdJu"
      },
      "source": [
        "### **Q1: Evaluate spaCy NER on CoNLL 2003 data (provided)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9wZqCN2KdJu"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "temporary_corpus = conll.read_corpus_conll(path)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF5d-QJXKdJu"
      },
      "source": [
        "nerDict= {\n",
        "    \"CARDINAL\": \"MISC\",\n",
        "    \"DATE\": \"MISC\",\n",
        "    \"EVENT\": \"MISC\",\n",
        "    \"FAC\": \"LOC\",\n",
        "    \"GPE\": \"LOC\",\n",
        "    \"LANGUAGE\": \"MISC\",\n",
        "    \"LAW\": \"MISC\",\n",
        "    \"LOC\": \"LOC\",\n",
        "    \"MONEY\": \"MISC\",\n",
        "    \"NORP\": \"MISC\",\n",
        "    \"ORDINAL\": \"MISC\",\n",
        "    \"ORG\": \"ORG\",\n",
        "    \"PERCENT\": \"MISC\",\n",
        "    \"PERSON\": \"PER\",\n",
        "    \"PRODUCT\": \"ORG\",\n",
        "    \"QUANTITY\": \"MISC\",\n",
        "    \"TIME\": \"MISC\",\n",
        "    \"WORK_OF_ART\": \"MISC\",\n",
        "    \"\": \"\"\n",
        "}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sep8ytuRKdJv"
      },
      "source": [
        "def convertNER(index):\n",
        "    sentenceArr=[]\n",
        "    tagLabel=[]\n",
        "    ref = []\n",
        "    hyp = []\n",
        "    for i in range(len(temporary_corpus[index])):\n",
        "        current_corpus = temporary_corpus[index][i][0].split()\n",
        "        sentenceArr.append(current_corpus[0])\n",
        "        tagLabel.append(current_corpus[-1])\n",
        "    if \"-DOCSTART-\" not in sentenceArr:\n",
        "        sentence = (\" \".join(sentenceArr))\n",
        "        doc = nlp(sentence)\n",
        "        for i in range(len(temporary_corpus[index])):\n",
        "            iob=doc[i].ent_iob_\n",
        "            ent_type=doc[i].ent_type_\n",
        "            cur_tag = \" \"\n",
        "            if iob==\"O\" or nerDict[ent_type]==\"\" :\n",
        "                cur_tag = \"O\"\n",
        "            else:\n",
        "                cur_tag = \"{}-{}\".format(iob, nerDict[ent_type])\n",
        "            \n",
        "            ref.append((str(doc[i]), cur_tag))\n",
        "            hyp.append((str(doc[i]), tagLabel[i]))\n",
        "        return ref, hyp\n",
        "    else:\n",
        "        return \"\",\"\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNycagEoKdJv"
      },
      "source": [
        "refs = []\n",
        "hyps = []\n",
        "for i in range(len(temporary_corpus)):  #for whole dataset\n",
        "#for i in range(100): #limited dataset for faster results\n",
        "    cur_ref, cur_hyp = convertNER(i)\n",
        "    if cur_ref == \"\":\n",
        "        continue\n",
        "    refs.append(cur_ref)\n",
        "    hyps.append(cur_hyp)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QST9-Vx_KdJv"
      },
      "source": [
        "ref_tags = [tag[1] for ref in refs for tag in ref]\n",
        "ref_labels = [tag[1] for hyp in hyps for tag in hyp]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfYxWdEwKdJv",
        "outputId": "8806e8a6-572f-4bf7-ba78-494a95b17e0e"
      },
      "source": [
        "## TOKEN EVAL\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(ref_labels, ref_tags))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.61      0.56      0.59      1668\n",
            "      B-MISC       0.08      0.51      0.14       702\n",
            "       B-ORG       0.46      0.31      0.37      1661\n",
            "       B-PER       0.58      0.46      0.51      1617\n",
            "       I-LOC       0.44      0.49      0.46       257\n",
            "      I-MISC       0.04      0.36      0.08       216\n",
            "       I-ORG       0.38      0.49      0.43       835\n",
            "       I-PER       0.51      0.56      0.53      1156\n",
            "           O       0.93      0.82      0.87     38323\n",
            "\n",
            "    accuracy                           0.76     46435\n",
            "   macro avg       0.45      0.51      0.44     46435\n",
            "weighted avg       0.85      0.76      0.80     46435\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BrfoK02KdJw",
        "outputId": "d5134695-4752-43f7-d87b-a5d641a31462"
      },
      "source": [
        "## CHUNK EVAL\n",
        "results = conll.evaluate(refs, hyps)\n",
        "print(pd.DataFrame().from_dict(results, orient='index').round(decimals=3))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           p      r      f     s\n",
            "MISC   0.484  0.080  0.137  4270\n",
            "ORG    0.264  0.402  0.319  1092\n",
            "PER    0.424  0.540  0.475  1271\n",
            "LOC    0.550  0.603  0.576  1522\n",
            "total  0.422  0.292  0.345  8155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAjlsa9JQNQk"
      },
      "source": [
        "### Q2: **Grouping of Entities. Write a function to group recognized named entities using noun_chunks method of spaCy. Analyze the groups in terms of most frequent combinations (i.e. NER types that go together).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY2xkUCEKdJx"
      },
      "source": [
        "def groupEnt(sentence):\n",
        "  \n",
        "\n",
        "def freqCount(groups):\n",
        "  dict_group = defaultdict(int)\n",
        "  for tok in groups:\n",
        "    key = \", \".join([i for i in tok])\n",
        "    dict_key[key] = dict_key[key] + 1\n",
        "  return dict_key\n",
        "\n",
        "groups = []\n",
        "freq = defaultdict(int)\n",
        "for sentence in tqdm(test[:]):\n",
        "  x = \" \".join([s[0] for s in sentence])\n",
        "  my_tokenization = [s[0] for s in sentence]\n",
        "  g = group(x)\n",
        "  frequency_group(g, freq)\n",
        "  groups.append(g)\n",
        "\n",
        "counts = pd.DataFrame().from_dict(freq, orient='index', columns=[\"Count\"]).sort_values(\"Count\", ascending=False)\n",
        "counts.round(decimals=3).head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppMhRhZ-Qnn-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}